# =============================
# íŒŒì´ì¬ ì½”ë“œ ì‹œì‘ (ì„í¬íŠ¸ ëª¨ë‘ ìƒë‹¨ ë°°ì¹˜)
# =============================
# import XXX  --> XXXë¼ëŠ” ëª¨ë“ˆ ì „ì²´ë¥¼ í˜„ì¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë¶™ì„(ë°”ì¸ë”©).  
# import math --> print(math.pi)
# from YYY  import XXX --> ëª¨ë“ˆ YYY ì•ˆì— ì •ì˜ëœ ì´ë¦„ XXX(í´ë˜ìŠ¤/í•¨ìˆ˜/ë³€ìˆ˜/ì„œë¸Œëª¨ë“ˆ ë“±)ë¥¼ ì§ì ‘ í˜„ì¬ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¡œ ë¶™ì„(ë°”ì¸ë”©). 
# from math import pi  --> print(pi)  

import os                          # ìš´ì˜ì²´ì œ ê²½ë¡œ, í™˜ê²½ë³€ìˆ˜ ì œì–´ â€” íŒŒì¼ ì €ì¥, ê²½ë¡œ ì¡°ì‘ ë“±ì— ì‚¬ìš©
import io                          # ë©”ëª¨ë¦¬ ë²„í¼ I/O â€” BytesIO, StringIO ë“± íŒŒì¼ì²˜ëŸ¼ ë‹¤ë£¨ëŠ” ê°ì²´ ì œê³µ
import tempfile                    # ì„ì‹œ íŒŒì¼/í´ë” ìƒì„± â€” ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ í›„ ì²˜ë¦¬ì— ì‚¬ìš©
from pathlib import Path           # ê²½ë¡œ ê°ì²´í™” â€” ê²½ë¡œ ì¡°ì‘ì„ ì§ê´€ì ì´ê³  í”Œë«í¼ ë…ë¦½ì ìœ¼ë¡œ ìˆ˜í–‰
from typing import List, Optional  # íƒ€ì… íŒíŠ¸ â€” List, Optional ë“±ìœ¼ë¡œ í•¨ìˆ˜ ì¸ì/ë°˜í™˜ íƒ€ì… ëª…ì‹œ
import streamlit as st             # Streamlit â€” ëŒ€í™”í˜• ì›¹ ì•± UI ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬
from loguru import logger          # Loguru â€” ê¹”ë”í•˜ê³  ê°•ë ¥í•œ ë¡œê¹… ê¸°ëŠ¥ ì œê³µ

# LangChain í•µì‹¬/ìœ í‹¸
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.schema import SystemMessage, HumanMessage # LangChainì—ì„œ ëŒ€í™”(ì±„íŒ…) ë©”ì‹œì§€ íƒ€ì… ë‘ ê°œë¥¼ ê°€ì ¸ì˜¤ëŠ”

# OpenAI / HF ì—°ê²° ëª¨ë“ˆ (ê³„ì† ì‚¬ìš©)
from langchain_openai import ChatOpenAI
from langchain_huggingface import HuggingFaceEmbeddings

# langchain_communityì—ì„œ ê¸°ë³¸ ì œê³µí•˜ëŠ” ë¬¸ì„œë¡œë”
# FAISS íŒŒì´ì“°ëŠ” í™˜ê²½ì— ë”°ë¼ import ì‹¤íŒ¨ ê°€ëŠ¥í•˜ë¯€ë¡œ try/exceptë¡œ ì²˜ë¦¬
try:                                                        # try ë¸”ë¡ ì‹œì‘, ë‹¤ìŒì— ì˜¤ëŠ” import ì‹œë„ë¥¼ í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ exceptë¡œ ë¶„ê¸°í•¨.
    from langchain_community.vectorstores import FAISS      # langchain_community íŒ¨í‚¤ì§€ ì•ˆì˜ vectorstores ëª¨ë“ˆì—ì„œ FAISS íŒŒì´ì“° í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê¸°
except Exception as _e:                                     # import ì¤‘ì— ì–´ë–¤ ì˜ˆì™¸ (ImportErrorë‚˜ ModuleNotFoundError)ê°€ ë°œìƒí•˜ë©´ ì—¬ê¸°ë¡œ ì˜¤ë©°, _eë¼ëŠ” ë³€ìˆ˜ì— ì˜ˆì™¸ ê°ì²´ê°€ ë‹´ê¸°ê²Œ ë¨.
    FAISS = None                                            # ì˜ˆì™¸ ë°œìƒ ì‹œ FAISS íŒŒì´ì“° ë³€ìˆ˜ë¥¼ Noneìœ¼ë¡œ ì„¤ì •í•¨.  
    _faiss_import_err = _e                                  # ì˜ˆì™¸ ê°ì²´(ì–´ë–¤ ì´ìœ ë¡œ importê°€ ì‹¤íŒ¨í–ˆëŠ”ì§€ì— ëŒ€í•œ ì •ë³´)ë¥¼ _faiss_import_err ë³€ìˆ˜ì— ì €ì¥í•¨.
                                                            # import ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë‹ˆ, ì•ˆì „í•˜ê²Œ Noneìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ëŒ€ì²´ ì €ì¥ì†Œë¥¼ ì„ íƒí•˜ë„ë¡ ì½”ë“œë¥¼ ì§œëŠ” ê²ƒì´ ì¼ë°˜ì ì„. 
                                                            # ê·¸ë˜ì„œ ì½”ë“œì—ì„œ if FAISS is None:ìœ¼ë¡œ ë¶„ê¸°í•˜ì—¬ Chroma, Milvus, Pinecone(ì›ê²©), Weaviate ë“± ë‹¤ë¥¸ vectorstoreë¡œ í´ë°±í•  ìˆ˜ë„ ìˆìŒ.
from langchain_community.document_loaders import (          # ì—¬ëŸ¬ ë¬¸ì„œ ë¡œë” í´ë˜ìŠ¤ë¥¼ í•œ ë²ˆì— import
    PyPDFLoader,            
    Docx2txtLoader,                  
    UnstructuredPowerPointLoader,
    TextLoader,                                             # return TextLoader(str(path), encoding="utf-8") >> TextLoader ì‚¬ìš© ì‹œ ì¸ì½”ë”©ì„ utf-8 ë° euc-kr ë“±ìœ¼ë¡œ ì„¤ì • ê°€ëŠ¥
)


# =============================
# í† í¬ë‚˜ì´ì €, ìŠ¤í”Œë¦¬í„°
# =============================
# í† í¬ë‚˜ì´ì €ëŠ” â€œí† í° ìˆ˜ë¥¼ ì•Œë ¤ì£¼ëŠ” ë„êµ¬â€ì´ë©°,
# í…ìŠ¤íŠ¸ìŠ¤í”Œë¦¬í„°ëŠ” ì˜ë¯¸ ë‹¨ìœ„(ë¬¸ë‹¨Â·ë¬¸ì¥Â·ì¤‘ì²© ê·œì¹™)Â·ì¤‘ë³µ(overlap)Â·ë©”íƒ€ë°ì´í„°ë¥¼ ê³ ë ¤í•´ ì‹¤ì œë¡œ ì²­í¬ë¥¼ ë§Œë“œëŠ” ë„êµ¬ì„.
# ë”°ë¼ì„œ í† í¬ë‚˜ì´ì €ì™€ í…ìŠ¤íŠ¸ìŠ¤í”Œë¦¬í„°ëŠ” í•¨ê»˜ ë³´ì™„í•˜ë©° ì‚¬ìš©í•´ì•¼í•˜ë©° ì•„ë˜ëŠ” ê·¸ ìƒì„¸ ì´ìœ :
# - í† í¬ë‚˜ì´ì €ë§Œ ìˆìœ¼ë©´ í† í° ê¸¸ì´ ì œì–´ëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ ë¬¸ì¥/ë¬¸ë‹¨ ê²½ê³„ë¥¼ ë¬´ì‹œí•˜ê³  ì˜ë¼ì„œ ì˜ë¯¸ íŒŒê´´(ì¤‘ê°„ ë¬¸ì¥ ì˜ë¦¼)ê°€ ì¼ì–´ë‚¨.
# - í…ìŠ¤íŠ¸ìŠ¤í”Œë¦¬í„°ëŠ” separator, chunk_size, chunk_overlap, prefer_sentence_boundary ê°™ì€ ê·œì¹™ì„ ì ìš©í•´ ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ë” ìì—°ìŠ¤ëŸ¬ìš´ ì²­í¬ë¥¼ ë§Œë“¦.
# - ê²€ìƒ‰,ì„ë² ë”©,LLM ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ìµœì í™”: ìŠ¤í”Œë¦¬í„°ëŠ” ì„ë² ë”©/ê²€ìƒ‰ íš¨ìœ¨ê³¼ LLM ì…ë ¥ í•œê³„ë¥¼ ì‹¤ì œ ìš´ì˜ ìš”êµ¬ì— ë§ì¶° ê´€ë¦¬.
# - ë©”ëª¨ë¦¬/ë©”íƒ€ë°ì´í„°: ê° ì²­í¬ì— ì¶œì²˜Â·ìœ„ì¹˜ ì •ë³´ë¥¼ ë¶™ì´ê¸° ì‰¬ì›€(ê²€ìƒ‰ ê²°ê³¼ì— ê·¼ê±° í‘œì‹œì— í•„ìš”).
# - ì„±ëŠ¥/ë¹„ìš©: ì ì ˆí•œ í¬ê¸°/ê²¹ì¹¨ìœ¼ë¡œ ë¶ˆí•„ìš”í•œ í† í° ë‚­ë¹„(=ë¹„ìš©)ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŒ.
#
# í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° (í† í¬ë‚˜ì´ì € ê¸°ë°˜ ë° ë¬¸ì ê¸°ë°˜ ëª¨ë‘ ì‚¬ìš©)
# langchain_text_splitters ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ RecursiveCharacterTextSplitter í´ë˜ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ê¸°
# ë¬¸ë‹¨/ë¬¸ì¥ ê²½ê³„ì™€ ì§€ì •í•œ ë¬¸ì ê¸¸ì´(chunk_size, chunk_overlap, separators ë“±)ë¥¼ ì´ìš©í•´ ë¬¸ì ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì²­í¬ë¥¼ ë§Œë“œëŠ” ë„êµ¬
from langchain_text_splitters import RecursiveCharacterTextSplitter

# í† í¬ë‚˜ì´ì €(tiktoken): ëª¨ë¸ í† í° ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ ìë¥´ê¸° ìœ„í•¨ â€” ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
# tiktokenì„ ì‚¬ìš©í•˜ë©´ ëª¨ë¸ì˜ í† í° ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•˜ê²Œ ìª¼ê°¤ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ë„ë¡ í•¨
# tiktokenì€ í…ìŠ¤íŠ¸ì™€ í† í°(í† í¬ë‚˜ì´ì €) ê°„ì— ì¸ì½”ë”©/ë””ì½”ë”©ì„ ë‹´ë‹¹í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì¨, ëª¨ë¸(OpenAIê³„ì—´)ì˜ í† í° ìˆ˜ë¥¼ ì •í™•íˆ ê³„ì‚°í•˜ê±°ë‚˜ í† í° ë‹¨ìœ„ë¡œ ë¶„í• í•  ë•Œ ì‚¬ìš©í•¨.
try:                                # try ë¸”ë¡ ì‹œì‘, ë‹¤ìŒì— ì˜¤ëŠ” ì½”ë“œ(ì—¬ê¸°ì„œëŠ” import tiktoken)ë¥¼ ì‹œë„í•˜ê³ , ì‹¤íŒ¨í•˜ë©´ exceptë¡œ ë¶„ê¸°ë©ë‹ˆë‹¤.
    import tiktoken                 # tiktoken ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ê¸°
except Exception as _tk_err:        # ì´ì „ import tiktokenì—ì„œ ì–´ë–¤ ì˜ˆì™¸ê°€ ë°œìƒí•˜ë©´(ëª¨ë“ˆì—†ìŒ,ë²„ì „ë¬¸ì œ ë“±) ì´ ë¸”ë¡ìœ¼ë¡œ ë“¤ì–´ì˜´. ì˜ˆì™¸ ê°ì²´ë¥¼ _tk_errë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë°›ë„ë¡í•¨.
    tiktoken = None                 # ì˜ˆì™¸ ë°œìƒ ì‹œ tiktoken ë³€ìˆ˜ë¥¼ Noneìœ¼ë¡œ ì„¤ì •
    _tiktoken_import_err = _tk_err  # ì˜ˆì™¸ ê°ì²´(_tk_err)ë¥¼ _tiktoken_import_errì— ì €ì¥í•¨


# =========================
# í† í° ì²­í¬ ì„¤ì • (í•„ìš” ì‹œ ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ë¨)
# =========================
TOKEN_ENCODING_NAME = "cl100k_base"  # TOKEN_ENCODING_NAME ë³€ìˆ˜ì— GPT-4/4o ê³„ì—´ê³¼ í˜¸í™˜ë˜ëŠ” í† í¬ë‚˜ì´ì € ì¸ì½”ë”© ì´ë¦„ "cl100k_base" í• ë‹¹
                                     # tiktoken ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì–´ë–¤ ì¸ì½”ë”©(í† í°í™” ê·œì¹™)ì„ ì“¸ì§€ ì§€ì •í•˜ëŠ” ë¬¸ìì—´ì„.
                                     # ëª¨ë¸ë³„(í˜¹ì€ í† í¬ë‚˜ì´ì €ë³„) ì¸ì½”ë”©ì´ ë‹¬ë¼ì„œ ë™ì¼í•œ ë¬¸ìì—´ì´ë¼ë„ í† í° ìˆ˜ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ.
TOKEN_CHUNK_SIZE = 800               # ì²­í¬ í•˜ë‚˜ì˜ ìµœëŒ€ í† í° ìˆ˜ (ë¬¸ì ì•„ë‹˜!)
                                     # í•˜ë‚˜ì˜ ë¬¸ì„œ ì²­í¬(ì¡°ê°)ê°€ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ í† í° ìˆ˜
                                     # ë¬¸ì(ê¸€ì ìˆ˜)ê°€ ì•„ë‹ˆë¼ í† í° ë‹¨ìœ„ë¼ëŠ” ì  ì¤‘ìš”í•¨ â€” í† í°ì€ ì–´ì ˆ/ë¶€ë¶„ì–´ì ˆ/ë¶€ë¶„ë¬¸ìì—´ ë‹¨ìœ„ë¡œ ë‚˜ë‰  ìˆ˜ ìˆìŒ.
TOKEN_CHUNK_OVERLAP = 80             # ì²­í¬ ê°„ ê²¹ì¹¨(í† í° ë‹¨ìœ„)
                                     # ì—°ì†ëœ ì²­í¬ë“¤ ì‚¬ì´ì— ì¤‘ë³µìœ¼ë¡œ í¬í•¨ë  í† í° ìˆ˜ë¥¼ ì˜ë¯¸í•¨(ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹)
                                     # ë¬¸ì¥/ë¬¸ë‹¨ ê²½ê³„ì—ì„œ ì •ë³´ ì†ì‹¤ì„ ì¤„ì´ê³ , ê²€ìƒ‰ ì‹œ ë¬¸ë§¥ ì—°ê²°ì„ ìœ ì§€í•˜ê²Œ í•¨. ë˜í•œ ìš”ì•½Â·ì„ë² ë”© ì‹œ ê²½ê³„ì—ì„œ ëŠê¸´ ì •ë³´ ë³´ì™„ìš©.
                                     # ë³´í†µ chunk_sizeì˜ 5~20% ìˆ˜ì¤€ì„ ë§ì´ ì‚¬ìš©(ì—¬ê¸°ì„  80/800 = 10%). ì ë‹¹í•œ ê°’ì€ ë¬¸ì„œ íŠ¹ì„±ì— ë”°ë¼ ì¡°ì •.


# =========================
# Streamlit ê¸°ë³¸ ì„¤ì •
# =========================
st.set_page_config(page_title="RAG Chatbot", page_icon="ğŸ¤–")                 # ë¸Œë¼ìš°ì € íƒ­ ì œëª©
st.title("CSS RAG Chatbot v0.6 âœ¨")                                                   # ì›¹í˜ì´ì§€ ìƒë‹¨ í°ì œëª©(í—¤ë”)
st.caption("ë¬¸ì„œê°€ ì—…ë¡œë“œëœ ê²½ìš°ëŠ” RAGë¡œ ë‹µë³€í•˜ê³ , ì—…ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš°ëŠ” LLMì—ì„œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.") # st.captionì€ ì§§ì€ ì•ˆë‚´ë¬¸ì— ì í•©, ê¸¸ê±°ë‚˜ í¬ë©§ìˆëŠ” í…ìŠ¤íŠ¸ëŠ” st.markdown() ë˜ëŠ” st.write() ì‚¬ìš©


# =========================
# ìœ í‹¸ë¦¬í‹°(í—¬í¼ í•¨ìˆ˜) ëª¨ìŒ
# =========================
def _persist_upload(file) -> Path:                      # _persist_upload í•¨ìˆ˜ëª…ì— file íŒŒë¼ë¯¸í„°ë¡œ ë°˜í™˜íƒ€ì…íŒíŠ¸ë¡œ(-> Path) pathlib.Path ê°ì²´ë¥¼ ë°˜í™˜ ì˜ˆì •
    tmp_dir = Path(tempfile.mkdtemp(prefix="st_docs_")) # mkdtempê°€ ìë™ìœ¼ë¡œ "st_docs_" ë’¤ì— ëœë¤ 8ìë¦¬ ê³ ì • ë¬¸ìì—´ì„ ë¶™ì—¬ ìƒˆ ë””ë ‰í† ë¦¬ë¥¼ ë§Œë“¤ê³  ê·¸ ì „ì²´ ê²½ë¡œ(ë¬¸ìì—´)ë¥¼ ë°˜í™˜ >> import tempfile, os
                                                        # ì¦‰ OS temp ì˜ì—­ì— ê³ ìœ í•œ ìƒˆë””ë ‰í† ë¦¬ ìƒì„±(ì˜ˆ:/tmp/st_docs_abcd1234) í›„ ê²½ë¡œ ë¬¸ìì—´ì„ ë°˜í™˜
    out_path = tmp_dir / file.name                      # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì›ë˜ ì´ë¦„(file.name)ì„ temp ë””ë ‰í† ë¦¬ ë‚´ì— íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•œ Pathë¥¼ ìƒì„±
    out_path.write_bytes(file.getbuffer())              # íŒŒì¼ ë‚´ìš© ë””ìŠ¤í¬ ê¸°ë¡ >> out_path.write_bytes(...)ëŠ” í•´ë‹¹ ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì¨ì„œ ì‹¤ì œ íŒŒì¼ì„ ìƒì„±
                                                        # file.getbuffer()ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë°”ì´íŠ¸ ë‚´ìš©ì„ ê°€ë¦¬í‚¤ëŠ” ê°ì²´(ë³´í†µ memoryview)ë¥¼ ë¦¬í„´(ë°˜í™˜)í•´ ì¤Œ
                                                        # memoryviewëŠ” ë³„ë„ì˜ ë³µì‚¬ ì—†ì´(ë˜ëŠ” ìµœì†Œí•œì˜ ë³µì‚¬ë¡œ) ë°ì´í„°ì˜ ì¼ë¶€ë¶„ì„ ì½ê±°ë‚˜ ìŠ¬ë¼ì´ìŠ¤í•  ìˆ˜ ìˆëŠ” ì¥ì  ì¡´ì¬í•¨
                                                        # file.getbuffer() vs file.read() ì°¨ì´ì 
                                                        # - file.read(): íŒŒì¼ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ bytes ê°ì²´ë¥¼ ë°˜í™˜ >> ë³µì‚¬ë³¸(ë©”ëª¨ë¦¬) ì¶”ê°€ ì°¨ì§€
                                                        # - file.getbuffer(): ì›ë³¸ ë°ì´í„°(ë²„í¼)ë¥¼ ê°€ë¦¬í‚¤ëŠ” ë·° ê°ì²´(memoryview)ë¥¼ ë°˜í™˜ >> ë³µì‚¬ë³¸(ë©”ëª¨ë¦¬) ì—†ì´ ì°¸ì¡°
    logger.info(f"ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {out_path}")          # logger(ì˜ˆ: loguru.logger)ë¥¼ ì‚¬ìš©í•´ ì €ì¥ëœ íŒŒì¼ ê²½ë¡œë¥¼ info ë ˆë²¨ë¡œ ê¸°ë¡ >> ë””ë²„ê¹…ìš©
    return out_path                                     # ì €ì¥ëœ íŒŒì¼ì˜ pathlib.Path ê°ì²´ë¥¼ í˜¸ì¶œìì—ê²Œ ë°˜í™˜ >> í˜¸ì¶œìëŠ” ë°˜í™˜ëœ ê²½ë¡œë¡œ íŒŒì¼ì„ ì—´ì–´ ë¡œë”ì— ì „ë‹¬í•˜ê±°ë‚˜ íŒŒì‹±í•˜ëŠ” ë“±ì˜ í›„ì† ì²˜ë¦¬í•¨.


def _load_document(path: Path):                         # _load_documentë¼ëŠ” í•¨ìˆ˜ì´ë©° path ì¸ìëŠ” pathlib.Path íƒ€ì…ì„ ê¸°ëŒ€í•œë‹¤ëŠ” ì˜ë¯¸(íƒ€ì…íŒíŠ¸) 
    ext = path.suffix.lower()                           # pathì˜ í™•ì¥ì(ë§ˆì§€ë§‰ ì ì„ í¬í•¨í•œ ë¶€ë¶„, ì˜ˆ:.pdf)ë¥¼ lower ì†Œë¬¸ìë¡œ ê°€ì ¸ì™€ extì— ì €ì¥ >> path.suffixëŠ” ë§ˆì§€ë§‰ í™•ì¥ìë§Œ ë°˜í™˜
    if ext == ".pdf":                                   # í™•ì¥ìê°€ .pdfì¸ì§€ ê²€ì‚¬
        return PyPDFLoader(str(path))                   # .pdfë©´ PyPDFLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ ë°˜í™˜ >> str(path)ë¡œ Pathë¥¼ ë¬¸ìì—´ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜í•´ì„œ ë¡œë”ì— ì „ë‹¬
    if ext in (".doc",".docx"):                         # í™•ì¥ìê°€ .doc ë˜ëŠ” docxì¸ì§€ ê²€ì‚¬
        return Docx2txtLoader(str(path))                # .docxë©´ Docx2txtLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜ >> str(path)ë¡œ Pathë¥¼ ë¬¸ìì—´ íŒŒì¼ ê²½ë¡œë¡œ ë³€í™˜í•´ì„œ ë¡œë”ì— ì „ë‹¬
    if ext in (".ppt", ".pptx"):                        # í™•ì¥ìê°€ .ppt ë˜ëŠ” .pptxì¸ì§€ ê²€ì‚¬
        return UnstructuredPowerPointLoader(str(path))  # .pptxë©´ UnstructuredPowerPointLoader ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜ 
    if ext == ".txt":                                   # í™•ì¥ìê°€ .txtì¸ì§€ ê²€ì‚¬ 
        return TextLoader(str(path), encoding="utf-8")  # í…ìŠ¤íŠ¸ íŒŒì¼ì´ë©´ TextLoaderë¥¼ ë°˜í™˜í•˜ê³ , ì¸ì½”ë”©ì„ utf-8ë¡œ ëª…ì‹œ >> euc-kr ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½ë„ ê°€ëŠ¥
    raise ValueError(f"ğŸ˜– ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {ext}")      # ìœ„ì˜ ì–´ëŠ ë¶„ê¸°ë„ ë§Œì¡±í•˜ì§€ ì•Šìœ¼ë©´(ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ìë©´) ValueError ì˜ˆì™¸ë¥¼ ë°œìƒ



# =========================
# ìºì‹œ: ì„ë² ë”©/ìŠ¤í”Œë¦¬í„° ê´€ë ¨ ì½”ë“œ ë¸”ë¡ ì˜ì—­
# =========================
@st.cache_resource(show_spinner=False)          # show_spinner=False ì˜µì…˜ì€ Streamlitì´ ë¡œë”© ì¤‘ì— ë³´ì—¬ì£¼ëŠ” íšŒì „ ìŠ¤í”¼ë„ˆë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŒì„ ì˜ë¯¸(ê¸°ë³¸ ìŠ¤í”¼ë„ˆ ìˆ¨ê¹€)
def get_hf_embeddings():                        # get_hf_embeddings() í•¨ìˆ˜(ì¸ìì—†ìŒ)ëŠ” ìºì‹œëœ ì„ë² ë”© ê°ì²´(HuggingFaceEmbeddings)ë¥¼ ë°˜í™˜
    return HuggingFaceEmbeddings(               # HuggingFaceEmbeddings í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ ë°˜í™˜ >> ì•„ë˜ì˜ í—ˆê¹…í˜ì´ìŠ¤ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ìºì‹œ)
                                                # ì´ ê°ì²´ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ Hugging Face Transformer ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ê³ , embed_documents() ë° embed_query() ê°™ì€ ë©”ì„œë“œë¡œ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©(ë²¡í„°)ìœ¼ë¡œ ë³€í™˜
        model_name="sentence-transformers/paraphrase-MiniLM-L6-v2",     # model_name: ì‚¬ìš©í•  Hugging Face ëª¨ë¸ì˜ ì‹ë³„ì(í—ˆê¹…í˜ì´ìŠ¤ í—ˆë¸Œ ì´ë¦„) >> paraphrase-MiniLM-L6-v2ëŠ” ê²½ëŸ‰ê¸‰ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸
        model_kwargs={"device": "cpu"},                                 # model_kwargs: ëª¨ë¸ ë¡œë“œ ì‹œ ì „ë‹¬í•  ì¶”ê°€ ì„¤ì • >> {"device": "cpu"}ëŠ” ëª¨ë¸ì„ CPUì—ì„œ ì‹¤í–‰í•˜ë„ë¡ ì„¤ì • >> GPU ì‚¬ìš©ê°€ëŠ¥í•˜ë©´ "cuda" ë˜ëŠ” {"device": "cuda:0"} ì„¤ì •
        encode_kwargs={"normalize_embeddings": True},                   # encode_kwargs: ì„ë² ë”©(ì¸ì½”ë”©) í˜¸ì¶œ ì‹œ ì‚¬ìš©í•  ì˜µì…˜ë“¤ >> {"normalize_embeddings": True}ëŠ” ìƒì„±ëœ ë²¡í„°ë¥¼ ì •ê·œí™”(L2-normalize) í•˜ì—¬ ë°˜í™˜
                                                                        # ê·¸ ì´ìœ ëŠ” ì •ê·œí™”ëœ ë²¡í„°ëŠ” FAISS íŒŒì´ì“°ì—ì„œ ê²€ìƒ‰ ì•ˆì •ì„±ì— ë„ì›€ >> inner-productë¥¼ cosine-similarity ì²˜ëŸ¼ ì•ˆì „í•˜ê²Œ ì‚¬ìš©í•˜ê±°ë‚˜, ê±°ë¦¬ ê³„ì‚° ì•ˆì •ì„±(ìŠ¤ì¼€ì¼ ì˜í–¥ ì œê±°)ì„ ë†’ì´ëŠ” ë° ë„ì›€ì´ë¨
        cache_folder="/tmp/hf",                                         # Hugging Face ëª¨ë¸/í† í¬ë‚˜ì´ì €ì˜ ë¡œì»¬ ìºì‹œ ë””ë ‰í„°ë¦¬ ê²½ë¡œ ì§€ì • >> ë§Œì•½ ì˜êµ¬ì ì¸ ì €ì¥ì´ í•„ìš”í•˜ë©´(ì¬ë¶€íŒ… í›„ ë³´ì¡´) ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ ì„¤ì •í•  ê²ƒ
    )


def _get_tiktoken_encoding(name: str):          # _get_tiktoken_encoding í•¨ìˆ˜ (íŒŒë¼ë¯¸í„° nameì€ ë¬¸ìì—´ string íƒ€ì…)
    if tiktoken is None:                        # ì „ì—­ ë³€ìˆ˜ tiktokenì´ Noneì¸ì§€(ì¦‰ import tiktoken ì‹¤íŒ¨í•´ì„œ ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ìƒíƒœì¸ì§€) ê²€ì‚¬í•˜ëŠ” ì¡°ê±´ë¬¸ >> Trueì´ë©´ ì•„ë˜ ì½”ë“œ(ì˜ˆì™¸ë°œìƒ)ë¥¼ ì‹¤í–‰
        raise RuntimeError(                     # RuntimeError ì˜ˆì™¸ë¥¼ ë°œìƒì‹œì¼œ í˜„ì¬ í•¨ìˆ˜(ë˜ëŠ” ì‹¤í–‰ íë¦„)ë¥¼ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ê³  ì˜ˆì™¸ë¥¼ í˜¸ì¶œì ìª½ìœ¼ë¡œ ì „ë‹¬
            f"tiktokenì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì›ì¸: {repr(_tiktoken_import_err)})\n"   # ì˜ˆì™¸ ë©”ì‹œì§€ f-stringìœ¼ë¡œ _tiktoken_import_errë¥¼ repr()ìœ¼ë¡œ ë¬¸ìì—´í™”í•´ì„œ ì™œ importê°€ ì‹¤íŒ¨í–ˆëŠ”ì§€ ìƒì„¸ ì •ë³´ë¥¼ í‘œì‹œí•¨
            "requirements.txtì— 'tiktoken'ì„ ì¶”ê°€í•˜ê³  ì¬ë°°í¬í•˜ì„¸ìš”."
        )
    try:                                            # ì•„ë˜ì— ì˜¤ëŠ” ë™ì‘(ì—¬ê¸°ì„œëŠ” tiktoken.get_encoding(name))ì„ ì‹œë„(try)í•˜ë˜, ì—ëŸ¬ê°€ ë‚˜ë©´ except ë¸”ë¡ìœ¼ë¡œ ì œì–´ë¥¼ ë„˜ê¸°ê² ë‹¤ëŠ” ëœ»ì´ë©° ë§Œì•½ ì—ëŸ¬ê°€ ì—†ìœ¼ë©´ try ë¸”ë¡ ë‚´ë¶€ê°€ ëë‚˜ê³  í•¨ìˆ˜ëŠ” ì •ìƒ ì¢…ë£Œë¨
        return tiktoken.get_encoding(name)          # tiktoken ëª¨ë“ˆì˜ get_encoding í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ ìš”ì²­í•œ ì¸ì½”ë”© ì´ë¦„(name)ì— í•´ë‹¹í•˜ëŠ” ì¸ì½”ë”© í•¸ë“¤(ì¸ì½”ë”/ë””ì½”ë” ê°ì²´) ì„ ë°˜í™˜
                                                    # ì´ë•Œ ë°˜í™˜ë˜ëŠ” ê°ì²´ëŠ” ë³´í†µ encode()ì´ë‚˜ decode() ê°™ì€ ë©”ì„œë“œë¥¼ ê°–ê³  ìˆì–´ì„œ í† í°í™”(ë¬¸ìì—´->í† í°) ë˜ëŠ” ì—­ë³€í™˜ë„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ
    except Exception:                               # try ì•ˆì˜ ì½”ë“œ ì‹¤í–‰ ì¤‘ ì–´ë–¤ ì˜ˆì™¸ì‚¬í•­ì´ë“  ë°œìƒí•˜ë©´ ì—¬ê¸°ë¡œ ë“¤ì–´ì˜´ 
        return tiktoken.get_encoding("cl100k_base") # í´ë°±(fallback) ë™ì‘ìœ¼ë¡œ tiktoken.get_encoding("cl100k_base") ë¥¼ í˜¸ì¶œí•´ ê·¸ ì¸ì½”ë”© í•¸ë“¤ì„ ë°˜í™˜
                                                    # ì¦‰ tryë¸”ë¡ì˜ get_encoding(name) í˜¸ì¶œì´ ì‹¤íŒ¨í•˜ë©´, ê¸°ë³¸ê°’ìœ¼ë¡œ cl100k_base ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ 
                                                    # í´ë°± == ì˜ì¡´ì„± ì—†ì„ ë•Œ/ì˜ˆì™¸ ë°œìƒí•  ë•Œì˜ ëŒ€ì²´ í–‰ë™ 


@st.cache_resource(show_spinner=False)              # Streamlit ë°ì½”ë ˆì´í„°. ì´ í•¨ìˆ˜ê°€ ë°˜í™˜í•˜ëŠ” ë¦¬ì†ŒìŠ¤(ê°ì²´)ë¥¼ ì•± ëŸ°íƒ€ì„ ë™ì•ˆ ìºì‹œ >> show_spinner=FalseëŠ” ë¡œë”© ì¤‘ì— Streamlitì˜ ë¡œë”© ìŠ¤í”¼ë„ˆë¥¼ ë³´ì—¬ì£¼ì§€ ì•ŠìŒ
def get_token_splitter(                             # get_token_splitter í•¨ìˆ˜ëŠ” í† í° ê¸°ì¤€ í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„°(ì²­í¬ ìƒì„±ê¸°)ë¥¼ ë°˜í™˜
    chunk_tokens: int = TOKEN_CHUNK_SIZE,           # chunk_tokens ì •ì˜(ì •ìˆ˜) = ê¸°ë³¸ê°’ì€ ì „ì—­ ìƒìˆ˜ TOKEN_CHUNK_SIZE (í† í° ë‹¨ìœ„ í•œ ì²­í¬ ìµœëŒ€ í¬ê¸°)
    overlap_tokens: int = TOKEN_CHUNK_OVERLAP,      # overlap_tokens ì •ì˜(ì •ìˆ˜) = ê¸°ë³¸ê°’ì€ ì „ì—­ ìƒìˆ˜ TOKEN_CHUNK_OVERLAP (ì¸ì ‘ ì²­í¬ ê°„ ì¤‘ì²© í† í° ìˆ˜)
    encoding_name: str = TOKEN_ENCODING_NAME,       # encoding_name ì •ì˜(ë¬¸ìì—´) = ê¸°ë³¸ê°’ì€ TOKEN_ENCODING_NAME (ì–´ë–¤ tiktoken ì¸ì½”ë”©ì„ ì“¸ì§€ ì§€ì •) >> (ì˜ˆ: "cl100k_base")
):
    _ = _get_tiktoken_encoding(encoding_name)       # _get_tiktoken_encoding(encoding_name)ë¥¼ í˜¸ì¶œí•´ í•´ë‹¹ ì¸ì½”ë”©ì´ ìœ íš¨í•œì§€(ê·¸ë¦¬ê³  tiktokenì´ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€) í™•ì¸
                                                    # ë§Œì•½ tiktokenì´ ì—†ê±°ë‚˜ ì¸ì½”ë”© ì¡°íšŒì— ì‹¤íŒ¨í•˜ë©´ _get_tiktoken_encodingì´ ì˜ˆì™¸ë¥¼ ë˜ì ¸ ì—¬ê¸°ì„œ í•¨ìˆ˜ ì‹¤í–‰ì´ ì¤‘ë‹¨ë¨
    return RecursiveCharacterTextSplitter.from_tiktoken_encoder(    # RecursiveCharacterTextSplitterì˜ í´ë˜ìŠ¤ë©”ì„œë“œ from_tiktoken_encoderë¥¼ í˜¸ì¶œí•˜ì—¬ í† í° ê¸°ì¤€ í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•´ ë°˜í™˜ >> ì´ ë°˜í™˜ê°’ì´ st.cache_resourceì— ì˜í•´ ìºì‹œë˜ì–´ ì¬ì‚¬ìš©
        chunk_size=chunk_tokens,                                    # from_tiktoken_encoder ì— ì „ë‹¬ë˜ëŠ” ì¸ì: chunk_sizeëŠ” í† í° ë‹¨ìœ„ë¡œ í•œ ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜(ìœ„ chunk_tokens)ë¡œ ì„¤ì •
        chunk_overlap=overlap_tokens,                               # chunk_overlap ì€ ì¸ì ‘ ì²­í¬ ê°„ ì¤‘ì²© í† í° ìˆ˜(ìœ„ overlap_tokens)ë¡œ ì„¤ì •
        encoding_name=encoding_name,                                # encoding_nameì€ tiktoken ì¸ì½”ë”© ì´ë¦„ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬(ì˜ˆ: "cl100k_base") >> ì´ ê°’ìœ¼ë¡œ í† í°í™”ë¥¼ ì •í™•íˆ ê³„ì‚°í•´ ë¬¸ì ê¸°ë°˜ ë¶„í• ì„ í† í° ë‹¨ìœ„ì— ë§ì¶° ìˆ˜í–‰
    )
 
 
# =========================
# ë²¡í„°ìŠ¤í† ì–´ ë¹Œë“œ
# =========================
def build_vectorstore(doc_paths: List[Path]):       # build_vectorstore í•¨ìˆ˜ (ì¸ì doc_pathsëŠ” pathlib.Pathë“¤ì˜ ë¦¬ìŠ¤íŠ¸ë¼ëŠ” íƒ€ì…íŒíŠ¸) >> ì£¼ì–´ì§„ ë¬¸ì„œ ê²½ë¡œ ëª©ë¡ì„ ì½ì–´ ì„ë² ë”©ì„ ë§Œë“¤ê³  FAISS íŒŒì´ì“° ë²¡í„°ìŠ¤í† ì–´(ì¸ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤)ë¥¼ ìƒì„±í•´ ë°˜í™˜
    if FAISS is None:                               # ìœ„ì—ì„œ ì´ì „ì— "try: from langchain_community.vectorstores import FAISS except: FAISS=None"ìœ¼ë¡œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ, FAISS íŒŒì´ì“°ê°€ import ì‹¤íŒ¨ë¡œ Noneì¸ì§€ í™•ì¸
        raise RuntimeError(                         # ì˜ˆì™¸ ë°œìƒ FAISSê°€ ì—†ìœ¼ë©´ ì¦‰ì‹œ RuntimeErrorë¥¼ ë°œìƒí•¨
            f"ğŸ˜– FAISS ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì›ì¸: {repr(_faiss_import_err)})\n"
            "CPU í™˜ê²½ì—ì„œëŠ” requirements.txtì— 'faiss-cpu'ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”.\n"
            "GPU í™˜ê²½ì—ì„œëŠ” requirements.txtì— 'faiss-gpu'ë¥¼ ì„¤ì •í•´ ì£¼ì„¸ìš”."
        )

    docs = []                                   # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”: ì´í›„ ë¡œë”ë¡œ ì½ì–´ë“¤ì¸ ë¬¸ì„œ(ë¬¸ì„œ ê°ì²´ë“¤)ë¥¼ ë‹´ì„ ì»¨í…Œì´ë„ˆ
    for p in doc_paths:                         # forë¬¸ ì‹œì‘ >> ì „ë‹¬ëœ ê° ë¬¸ì„œ ê²½ë¡œ pì— ëŒ€í•´ ì²˜ë¦¬
        loader = _load_document(p)              # ë¬¸ì„œ ë¡œë” ì„ íƒ >> _load_document(path) í•¨ìˆ˜ë¡œ íŒŒì¼ í™•ì¥ìì— ë§ëŠ” ë¡œë”(PyPDFLoader, Docx2txtLoader, UnstructuredPowerPointLoader, TextLoader ë“±)ë¥¼ ìƒì„±/ë°˜í™˜ ë°›ìŒ
        docs.extend(loader.load())              # ë¬¸ì„œ ì½ê¸° ë° ëˆ„ì  >> loader.load()ë¥¼ í˜¸ì¶œí•´ ê·¸ íŒŒì¼ì—ì„œ ì¶”ì¶œí•œ Document ê°ì²´ë“¤(ë³´í†µ í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° í¬í•¨)ì„ ë°˜í™˜ë°›ì•„ docs ë¦¬ìŠ¤íŠ¸ì— í™•ì¥(extend)ìœ¼ë¡œ ì¶”ê°€
                                                # ê²°ê³¼ë¡œ docsëŠ” ëª¨ë“  ì…ë ¥ íŒŒì¼ì—ì„œ ì½ì–´ì˜¨ ì›ë¬¸ ì²­í¬(ë˜ëŠ” ì›ë¬¸ í˜ì´ì§€)ë“¤ì˜ ë¦¬ìŠ¤íŠ¸ê°€ ë¨

    splitter = get_token_splitter()             # í† í° ê¸°ë°˜ ìŠ¤í”Œë¦¬í„° ìƒì„± >> get_token_splitter()ëŠ” ìœ„ì˜ RecursiveCharacterTextSplitter.from_tiktoken_encoder(...)ë¡œ ìƒì„±ëœ ìŠ¤í”Œë¦¬í„°(í† í°ë‹¨ìœ„ë¡œ chunk_size/overlapì„ ì •í™•íˆ ë§ì¶¤)ë¥¼ ë°˜í™˜
                                                # í† í° ë‹¨ìœ„ ë¶„í• ì„ ì‚¬ìš©í•´ LLM ì»¨í…ìŠ¤íŠ¸/ì„ë² ë”© ëª©ì ì— ë§ëŠ” ì²­í¬ë¥¼ ë§Œë“¤ê² ë‹¤ëŠ” ì˜ë¯¸ >> í† í° ë‹¨ìœ„ ìŠ¤í”Œë¦¬í„° ì‚¬ìš©
    splits = splitter.split_documents(docs)     # ë¬¸ì„œ ë¶„í•  ì‹¤í–‰: splitter.split_documents(docs)ëŠ” docsì˜ ê° ë¬¸ì„œë¥¼ í† í° ê¸°ì¤€ìœ¼ë¡œ ì˜ë¼ ì—¬ëŸ¬ ì²­í¬(ë¬¸ì„œ ì¡°ê°)ë¥¼ ìƒì„±í•¨
                                                # ê·¸ ë°˜í™˜ê°’ splitsëŠ” ì²­í¬(ê° ì²­í¬ë„ Document íƒ€ì…ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë° ë©”íƒ€ í¬í•¨)ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ, ì´ê±¸ ì„ë² ë”©/ìƒ‰ì¸ì— ì…ë ¥í•˜ê²Œ ë¨
    embeddings = get_hf_embeddings()            # ì„ë² ë”© ëª¨ë¸ í•¸ë“¤ íšë“: get_hf_embeddings()ëŠ” ìºì‹œëœ HuggingFaceEmbeddings ì¸ìŠ¤í„´ìŠ¤(ì˜ˆ: sentence-transformers/paraphrase-MiniLM-L6-v2)ë¥¼ ë°˜í™˜
                                                # ì´ ê°ì²´ëŠ” .embed_documents() ë˜ëŠ” LangChain ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ ë¬¸ì„œë“¤ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ë° ì‚¬ìš©ë¨
    vectorstore = FAISS.from_documents(splits, embeddings)  # FAISS ì¸ë±ìŠ¤ ìƒì„±: FAISS.from_documents(splits, embeddings)ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰:
                                                            # 1) splitsì˜ ê° ì²­í¬ í…ìŠ¤íŠ¸ì— ëŒ€í•´ embeddingsë¥¼ ì‚¬ìš©í•´ ë²¡í„°(ì„ë² ë”©)ë¥¼ ê³„ì‚°
                                                            # 2) ê³„ì‚°ëœ ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„°(ë¬¸ì„œ ì¶œì²˜, í…ìŠ¤íŠ¸ ë“±)ë¥¼ FAISS íŒŒì´ì“° ì¸ë±ìŠ¤ì— ì‚½ì…í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
                                                            # ê²°ê³¼: vectorstoreëŠ” ê²€ìƒ‰(ìœ ì‚¬ë„ê²€ìƒ‰)ì„ ì§€ì›í•˜ëŠ” ê°ì²´ (ë©”ëª¨ë¦¬ ë‚´ FAISS Index wrapper) >> í•„ìš”í•˜ë©´ ì´í›„ vectorstore.search(...)ë¡œ ì¿¼ë¦¬í•  ìˆ˜ ìˆìŒ.
    return vectorstore                          # ì™„ì„±ëœ FAISS íŒŒì´ì“° ë²¡í„°ìŠ¤í† ì–´ ê°ì²´ë¥¼ í˜¸ì¶œìì—ê²Œ ë°˜í™˜ >> í˜¸ì¶œìëŠ” ì´ ê°ì²´ë¥¼ retrieverë¡œ ê°ì‹¸ê±°ë‚˜ ConversationalRetrievalChainì— ë„£ì–´ RAG(ë¬¸ì„œê¸°ë°˜ì‘ë‹µ) ì²´ì¸ì„ ì œê³µ

    
# =========================
# ì²´ì¸ êµ¬ì„± (LLM + Retriever + ë©”ëª¨ë¦¬)
# =========================
def get_chain(vectorstore, openai_api_key: str):
    """ConversationalRetrievalChain êµ¬ì„±
    - LLMì€ OpenAI (gpt-4o-mini) ì‚¬ìš©
    - retrieverëŠ” FAISS.as_retriever(search_type="mmr") ì‚¬ìš©
    - ë©”ëª¨ë¦¬ëŠ” ëŒ€í™” ê¸°ë¡ì„ LLMì— ì œê³µ (ë‹µë³€ í’ˆì§ˆ í–¥ìƒ)
    """
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        model="gpt-4o-mini",  # ì €ë ´ & ë¹ ë¦„ (í•„ìš” ì‹œ gpt-4o ë¡œ êµì²´ ê°€ëŠ¥)
        temperature=0,        # 0: ì°½ì˜ì„± ë‚®ì¶”ê³ , ì¼ê´€ì„± ë†’ì€ ë‹µë³€ ìƒì„±
        max_retries=3,        # ê°„ë‹¨í•œ ì¬ì‹œë„ (429 ë“± ë ˆì´íŠ¸ë¦¬ë°‹ ëŒ€ë¹„)
        timeout=10,           # 10ì´ˆ ì´ìƒ ê±¸ë¦¬ë©´ ìš”ì²­ ì¤‘ë‹¨
    )

    memory = ConversationBufferMemory(
        memory_key="chat_history",  # ì²´ì¸ ë‚´ë¶€ì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ì°¾ì„ ë•Œ ì“°ëŠ” í‚¤ ì´ë¦„
        return_messages=True,       # ëŒ€í™” ë©”ì‹œì§€ ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        output_key="answer",        # ìµœì¢… ìƒì„±ëœ ë‹µë³€ì˜ í‚¤ ì´ë¦„
    )

    retriever = vectorstore.as_retriever(search_type="mmr")
    #  - vectorstore: ì—…ë¡œë“œëœ ë¬¸ì„œ ì„ë² ë”©ì„ ì €ì¥í•œ FAISS ë²¡í„° DB
    #  - retriever: ì§ˆë¬¸ì„ ì„ë² ë”©í•˜ì—¬ ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰
    #  - search_type="mmr": ì¤‘ë³µì„ ì¤„ì´ê³  ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ëŠ” ê²€ìƒ‰ ì „ëµ

    chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=retriever,
        chain_type="stuff",           # ì²­í¬ë¥¼ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ì— ìŠ¤í„°í•‘(stuff)í•˜ëŠ” ê°„ë‹¨í•œ ë°©ì‹
        memory=memory,
        get_chat_history=lambda h: h, # ëŒ€í™” ë‚´ì—­ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
        return_source_documents=True, # ì°¸ì¡°í•œ ì›ë¬¸ ì²­í¬ê¹Œì§€ í•¨ê»˜ ë°˜í™˜
        verbose=True,                 # ë””ë²„ê¹… ë¡œê·¸
    )
    return chain


# =========================
# LLM ë‹¨ë…(ë¹„ RAG) ì‘ë‹µ í—¬í¼
# =========================
def answer_without_rag(question: str, openai_api_key: str) -> str:
    """ë¬¸ì„œ ì¸ë±ìŠ¤ê°€ ì—†ì„ ë•Œ, LLMë§Œìœ¼ë¡œ ê°„ê²°í•œ ë‹µë³€ì„ ìƒì„±
    - 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ì§§ê³  í•µì‹¬ë§Œ
    - RAGê°€ ì•„ë‹˜ì„ UIì—ì„œ ë³„ë„ ì•ˆë‚´
    """
    llm = ChatOpenAI(
        openai_api_key=openai_api_key,
        model="gpt-4o-mini",
        temperature=0,
        max_retries=3,
        timeout=10,
    )
    sys = SystemMessage(content="ë„ˆëŠ” ê°„ê²°í•œ ì¡°ìˆ˜ë‹¤. ëª¨ë“  ë‹µë³€ì€ 2~3ë¬¸ì¥ ì´ë‚´ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì„œ ë§í•´ë¼.")
    user = HumanMessage(content=question)
    resp = llm.invoke([sys, user])  # Chat ëª¨ë¸ì˜ invoke ì‚¬ìš©
    return getattr(resp, "content", str(resp))


# =========================
# ì‚¬ì´ë“œë°”(UI): API í‚¤/ë¬¸ì„œ ì—…ë¡œë“œ/ì¸ë±ìŠ¤ ë²„íŠ¼
# =========================
with st.sidebar:
    st.subheader("ğŸ”‘ OpenAI API Key")

    # ê¸°ë³¸ê°’: Streamlit Secretsì— OPENAI_API_KEYê°€ ìˆë‹¤ë©´ ìë™ ì‚¬ìš©
    default_key = st.secrets.get("OPENAI_API_KEY", "") if hasattr(st, "secrets") else ""
    openai_api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=default_key,
        help="Streamlit Cloudì˜ Secretsì— OPENAI_API_KEYë¥¼ ë“±ë¡í•˜ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
    )

    uploaded_files = st.file_uploader(
        "1MB ë¯¸ë§Œ ë¬¸ì„œ ì—…ë¡œë“œ ê¶Œì¥ (PDF/DOCX/PPTX/TXT)",   # ì•ˆë‚´ ë¬¸êµ¬ì— TXT ì¶”ê°€
        type=["pdf", "docx", "pptx", "txt"],  #  txt í™•ì¥ì í—ˆìš©
        accept_multiple_files=True,
    )

    build_btn = st.button("ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±")


# =========================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# =========================
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "chain" not in st.session_state:
    st.session_state.chain = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


# =========================
# ì¸ë±ìŠ¤ ë¹Œë“œ ì‹¤í–‰
# =========================
if build_btn:
    if not openai_api_key:
        st.error("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not uploaded_files:
        st.warning("ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        with st.spinner("ë²¡í„° ì¸ë±ì‹± ì¤‘â€¦ (ìµœì´ˆì—ëŠ” ëª¨ë¸/í† í¬ë‚˜ì´ì € ë¡œë”© ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
            try:
                doc_paths = [_persist_upload(f) for f in uploaded_files]
                vs = build_vectorstore(doc_paths)
                st.session_state.vectorstore = vs
                st.session_state.chain = get_chain(vs, openai_api_key)
                st.success("âœ… Vector Index ìƒì„± ì™„ë£Œ! (RAG ê°€ëŠ¥)")
            except Exception as e:
                logger.exception("Vector Index ì‹¤íŒ¨")
                st.error(f"ğŸ˜– ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")


# =========================
# ì§ˆì˜ UI
# =========================
st.divider()
st.subheader("ğŸ’¬ ë¬¸ì„œ ê¸°ë°˜ ìì—°ì–´ ì§ˆë¬¸")
user_q = st.text_input("ì§ˆë¬¸ ì…ë ¥:", placeholder="ì˜ˆ: ì—…ë¡œë“œí•œ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì§ˆë¬¸ì„ í•´ ë³´ì„¸ìš”.")
ask = st.button("ì§ˆë¬¸í•˜ê¸°")


# =========================
# QA ì‹¤í–‰ (RAG ON/OFF í´ë°± í¬í•¨)
# =========================
if ask:
    if not openai_api_key:
        st.error("ğŸ”‘ OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not user_q.strip():
        st.info("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        # 1) ì¸ë±ìŠ¤/ì²´ì¸ ì¤€ë¹„ ì—¬ë¶€ í™•ì¸
        if st.session_state.chain is None:
            # ğŸ” í´ë°±: ë¬¸ì„œ ì¸ë±ìŠ¤ê°€ ì—†ìœ¼ë¯€ë¡œ LLM ë‹¨ë… ê°„ë‹¨ ë‹µë³€
            with st.spinner("LLM ë‹µë³€ ìƒì„± ì¤‘â€¦ (RAG: OFF)"):
                try:
                    answer = answer_without_rag(user_q, openai_api_key)
                    st.session_state.chat_history.append(("user", user_q))
                    st.session_state.chat_history.append(("assistant", answer))

                    st.markdown("### ğŸ§  ë‹µë³€  `RAG: OFF`")
                    # st.write(answer)
                    st.text(answer)  #  í•œê¸€/ì˜ë¬¸ ì„œì‹ì„ ì œê±°í•˜ê³  'ìˆœìˆ˜ í…ìŠ¤íŠ¸'ë¡œ í‘œì‹œí•˜ì—¬ ê¸€ê¼´ ì°¨ì´ë¥¼ ì—†ì•°
                    st.info("RAG ë¹„í™œì„±í™” ìƒíƒœì…ë‹ˆë‹¤. ì—…ë¡œë“œí•œ ë¬¸ì„œê°€ ì—†ì–´ LLM ë§Œìœ¼ë¡œ ê°„ë‹¨íˆ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.")
                except Exception as e:
                    logger.exception("LLM-Only ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨")
                    st.error(f"ğŸ˜– ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨(LLM-Only): {e}")
        else:
            # âœ… RAG ê²½ë¡œ
            with st.spinner("RAG ì‘ë‹µ ìƒì„± ì¤‘â€¦ (RAG: ON)"):
                try:
                    result = st.session_state.chain({"question": user_q})
                    answer = result.get("answer", "(ë‹µë³€ ì—†ìŒ)")
                    sources = result.get("source_documents", [])

                    st.session_state.chat_history.append(("user", user_q))
                    st.session_state.chat_history.append(("assistant", answer))

                    st.markdown("### ğŸ§  ë‹µë³€  `RAG: ON`")
                    # st.write(answer)
                    st.text(answer)  #  í•œê¸€/ì˜ë¬¸ ì„œì‹ì„ ì œê±°í•˜ê³  'ìˆœìˆ˜ í…ìŠ¤íŠ¸'ë¡œ í‘œì‹œí•˜ì—¬ ê¸€ê¼´ ì°¨ì´ë¥¼ ì—†ì•°
                  
                    # ê·¼ê±° ë¬¸ì„œ í‘œì‹œ
                    if sources:
                        st.markdown("### ğŸ’¡ ì°¸ê³  ë¬¸ì„œ")
                        with st.expander("ì°¸ê³  ë¬¸ì„œ ìœ„ì¹˜ ë° ì›ë¬¸ ì¼ë¶€ ë³´ê¸°"):
                            for i, doc in enumerate(sources, 1):
                                src = doc.metadata.get("source", f"source_{i}")
                                st.markdown(f"**{i}.** {src}")
                                preview = (doc.page_content or "").strip()
                                if len(preview) > 600:
                                    preview = preview[:600] + " â€¦"
                                st.code(preview)
                    else:
                        st.info("í•´ë‹¹ ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” ë¬¸ì„œ ì²­í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì§ˆë¬¸ì„ ë” êµ¬ì²´í™”í•˜ê±°ë‚˜ ì¸ë±ì‹± ë²”ìœ„ë¥¼ ëŠ˜ë ¤ ë³´ì„¸ìš”.)")
                except Exception as e:
                    logger.exception("ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨(RAG)")
                    st.error(f"ğŸ˜– ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨(RAG): {e}")


# =========================
# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
# =========================
if st.session_state.chat_history:
    st.divider()
    st.subheader("ğŸ—‚ï¸ ì„¸ì…˜ ì•„ì¹´ì´ë¸Œ")
    for role, msg in st.session_state.chat_history[-10:]:
        if role == "user":
            st.markdown(f"**You:** {msg}")
        else:
            st.markdown(f"**Assistant:** {msg}")
